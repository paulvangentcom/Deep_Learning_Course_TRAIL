{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bMNDtOiK8DUW"
   },
   "source": [
    "# Exercise 3 - Structuring Your Deep Learning Project\n",
    "\n",
    "Many modern digital cameras and camera apps on your phone do face recognition. Usually you see them draw a square around a detected face and make sure it is in focus:\n",
    "\n",
    "![face detection on sony A6000](http://www.paulvangent.com/files/DL_Course/day2_images/FaceRec.jpg)\n",
    "\n",
    "How hard could this be? You're all smart engineers so let's figure this out! At the end of this notebook you will know how to build such a system.\n",
    "\n",
    "In this notebook you'll learn how to set up a default project structure when approaching a new deep learning problem. You will build several 'building blocks' that you can re-use later on. This way, each time you start a new project, you will be on your way faster.\n",
    "\n",
    "The focus in this notebook is on writing simple and reusable functions.\n",
    "\n",
    "### Index\n",
    "- 3.1 - Preprocessing your dataset\n",
    "- 3.2 - Options for loading your dataset\n",
    "    - loading into RAM\n",
    "    - memory mapping large set\n",
    "    - dynamic loading  with data generator\n",
    "- 3.3 - Visualising your training data\n",
    "- 3.4 - Fitting the model\n",
    "    - Monitoring performance: warning signs\n",
    "    - Early Stopping\n",
    "- 3.5 - Testing and visualising results\n",
    "\n",
    "Let's get started! Run the cell below to import everything required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "GUCLMEU08DUX",
    "outputId": "a02cfd47-b65b-4b06-9da2-bfbc55b84d05"
   },
   "outputs": [],
   "source": [
    "#download required datasets for this notebook (might take a bit, be patient!)\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def download(url, file):\n",
    "    if os.path.isfile(file):\n",
    "        os.remove(file)\n",
    "    if not os.path.isfile(file):\n",
    "        print(\"Download file... \" + file + \" ...\")\n",
    "        urlretrieve(url,file)\n",
    "        print(\"File downloaded\")\n",
    "        \n",
    "def unzip(file):\n",
    "    with ZipFile(file) as f:\n",
    "        f.extractall()\n",
    "    print('unzipped file: %s\\n' %file)\n",
    "    \n",
    "    \n",
    "try:\n",
    "    download('http://www.paulvangent.com/files/DL_Course/misc_day2.zip', 'misc_day2.zip')\n",
    "except:\n",
    "    download('https://onedrive.live.com/download?cid=39383A5AFCD95065&resid=39383A5AFCD95065%21754608&authkey=AOJO5mcV9eCZsJ8', 'misc_day2.zip')\n",
    "unzip('misc_day2.zip')\n",
    "\n",
    "try:\n",
    "    download('http://www.paulvangent.com/files/DL_Course/test_images.zip', 'test_images.zip')\n",
    "except:\n",
    "    download('https://onedrive.live.com/download?cid=39383A5AFCD95065&resid=39383A5AFCD95065%21754595&authkey=AETVSL8bPBIpTnI', 'test_images.zip')\n",
    "unzip('test_images.zip')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "from keras.datasets import cifar10\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "import utils_day2 as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNyv3ET_8DUb"
   },
   "source": [
    "## 3.1 Preprocessing your dataset\n",
    "\n",
    "The first thing you'll do is build a preprocessing function that encompasses what you learned in exercise two. We will again use the subset of the CelebA dataset and this time include the bounding boxes annotated around the faces:\n",
    "\n",
    "![bb examples](http://www.paulvangent.com/files/DL_Course/day2_images/bb_examples.jpg)\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "Make a pre-processing function. We made this one a bit more complex to keep you challenged.\n",
    "\n",
    "- It should take an image and face boundingbox label as arguments\n",
    "- It should normalize or standardize the input image (your choice, what you think is best)\n",
    "- Realize that when you scale the image, you also  need to scale the bounding box!\n",
    "    - the annotation format is: *[x1, y1, width, height]*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "r-EJZHtn8DUc",
    "outputId": "d6ad12b2-da10-415d-ebbe-81df755fa8d9"
   },
   "outputs": [],
   "source": [
    "###Start coding segment###\n",
    "#Complete the code below.\n",
    "\n",
    "def pre_process(image, label, max_size=100):\n",
    "    '''\n",
    "    function takes in image and label\n",
    "    along with max_size argument.\n",
    "    \n",
    "    returns normalized and resizedimage and label\n",
    "    '''\n",
    "\n",
    "    \n",
    "    \n",
    "    return resized, label\n",
    "\n",
    "###End of coding segment###\n",
    "\n",
    "#Let's get a random image and annotation for it\n",
    "img = cv2.imread('celeba_larger/data/101861.jpg')\n",
    "annotations = pd.read_csv('celeba_larger/labels/list_bbox_celeba.txt')\n",
    "bb1 = annotations[1861:1862].values[0][1:]\n",
    "\n",
    "#Here we call your pre-processing function to resize the image and the label\n",
    "img, bb1 = pre_process(img, bb1, max_size=100)\n",
    "\n",
    "#Let's draw your resized boundingbox on the resized image to check\n",
    "#note that cv2.rectangle wants [x,y] for top left and bottom right corners, not width and height!\n",
    "img = cv2.rectangle(img, (bb1[0], bb1[1]), (bb1[0]+bb1[2], bb1[1]+bb1[3]), (0,0,255), thickness=2)\n",
    "\n",
    "#And visualise\n",
    "plt.imshow(img[...,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GdK4jgfB8DUe"
   },
   "source": [
    "If you find that your bounding box does not match the face, see where you went wrong. Did you mix up dimensions? Did you not scale properly? What else can you have done wrong?\n",
    "\n",
    "-------------\n",
    "\n",
    "## 3.2 Loading data\n",
    "\n",
    "Before feeding training data to the network you need to load it. You basically have three options. We'll explore each briefly, although we'll say now that the data generator (see also exercise 1 of today) is superior both in flexibility and re-usability.\n",
    "\n",
    "In this section we'll show you how to use all three methods.\n",
    "\n",
    "You'll work with both the cifar10 dataset, and a subset of the [celebA dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html).\n",
    "\n",
    "### Loading your data into RAM\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "Complete the code below to load the dataset into memory.\n",
    "\n",
    "- Use data type 'unsigned 8bit integer' (np.uint8)\n",
    "- cifar10 has 50.000 images of 32x32x3 each (32x32pixels, 3 color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eh5WHsXp8DUf",
    "outputId": "9cad653e-367d-4f41-dae3-99cf63d72af3"
   },
   "outputs": [],
   "source": [
    "#load images\n",
    "(X_train, Y_train), _ = cifar10.load_data()\n",
    "\n",
    "###Start of coding segment###\n",
    "#Complete the code below (approx. 2 lines)\n",
    "#define arrays filled with zeros\n",
    "X = \n",
    "Y = \n",
    "\n",
    "#Complete the code below (approx. 2 lines)\n",
    "#put images and labels into the arrays we just created\n",
    "for i in range(len(X_train)):\n",
    "    X[i] = \n",
    "    Y[i] = \n",
    "    \n",
    "###End of coding segment###\n",
    "\n",
    "#this section shows the memory footprint of the objects\n",
    "footprint_X = utils.get_size(X)\n",
    "footprint_Y = utils.get_size(Y)\n",
    "\n",
    "print('training object uses: %f MB\\nlabel object uses: %f MB' %(footprint_X / 1000000,\n",
    "                                                                footprint_Y / 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJ0LKJXk8DUh"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "------------\n",
    "training object uses: 153.600626 MB\n",
    "\n",
    "label object uses: 0.050146 MB\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "**Advantages of loading data into RAM**\n",
    "\n",
    "- It allows for fast access times, meaning fetching of training data will not be a bottleneck\n",
    "- It's very easy to write a 'quick and dirty' solution no matter how the data is structured\n",
    "\n",
    "**Drawbacks of loading data into RAM**\n",
    "\n",
    "![more ram?](http://www.paulvangent.com/files/DL_Course/day2_images/moreram.jpg)\n",
    "\n",
    "- Almost no modern deep learning dataset will fit in RAM.\n",
    "- Image data will take a lot more space in RAM than the file on the disk, as it will be loaded as an uncompressed array.\n",
    "- If you exceed the available RAM, your OS will start swapping portions to disk. \n",
    "    - *This potentially creates worse slowdowns than when using the other two approaches*\n",
    "\n",
    "**When to use?**\n",
    "\n",
    "Ideally never. However for datasets not requiring much space (some types of numerical sensor-data for example) you could choose this option.\n",
    "\n",
    "--------\n",
    "\n",
    "### Memory mapped objects\n",
    "\n",
    "A memory mapped object stores all its data on the hard drive, and maps that to a virtual memory space. This means Python can access all data as if the data were loaded into RAM, except the actual data is stored on disk.\n",
    "\n",
    "Let's give that a try.\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "Complete the code below to create a memory-mapped object storing the first 10000 images from cifar10. Cifar10 contains images of 32x32x3 pixels (colour images)\n",
    "\n",
    "[Hint](https://docs.scipy.org/doc/numpy/reference/generated/numpy.memmap.html)\n",
    "\n",
    "**Note** that in this example, we use cifar10 for simplicity's sake, because the memmap requires a well-defined shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6lWeuHKJ8DUi",
    "outputId": "fc3f15fb-804d-4c03-dbfa-d9739d170b83"
   },
   "outputs": [],
   "source": [
    "#Complete the code below (approx. 2 lines)\n",
    "#create memmap\n",
    "X = np.memmap(...)\n",
    "Y = np.memmap(...)\n",
    "\n",
    "#Complete the code below (approx. 2 lines)\n",
    "#write files to memmap\n",
    "for i in range(len(X_train)):\n",
    "\n",
    "       \n",
    "#this section shows the memory footprint of the objects\n",
    "footprint_X = utils.get_size(X)\n",
    "footprint_Y = utils.get_size(Y)\n",
    "\n",
    "print('training memmap uses: %f MB\\nlabel memmap uses: %f MB' %(footprint_X / 1000000,\n",
    "                                                                footprint_Y / 1000000))\n",
    "#you close the memmap by deleting the object\n",
    "#this allows the OS to write changes to disk, so always close it after use!\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mn0wI7Zb8DUk"
   },
   "source": [
    "Expected output:\n",
    "\n",
    "-------\n",
    "training memmap uses: 0.001827 MB\n",
    "\n",
    "label memmap uses: 0.001258 MB\n",
    "\n",
    "-------\n",
    "\n",
    "Even though the same data is being used, the memory mapped object only uses 0.002 MegaBytes, compared to 153 MegaBytes for when loading all images into an array in memory. Note that the memmap file is not magic: it *will* claim 153MB on the harddrive in stead! Hard drives are many times larger than RAM so this is not always a problem.\n",
    "\n",
    "**Advantages of using a memory mapped object**\n",
    "\n",
    "- You can work with datasets that don't fit in your RAM, provided you have the disk space.\n",
    "- It allows for parallel access. \n",
    "    - If you have multiple GPUs, this means you can train multiple models simultaneously without needing extra RAM or disk space for the training data.\n",
    "- memmap files work just like numpy arrays, so you already know how to work with them!\n",
    "- It's very easy to write a 'quick and dirty' solution no matter how the data is structured\n",
    "\n",
    "**Drawbacks of using a memory mapped object**\n",
    "\n",
    "- Data will still need to be read from disk, which is relatively slow\n",
    "- Especially image data will be much larger than when stored in jpeg format\n",
    "    - Just like when loading into ram it is stored in uncompressed binary format. The only difference is *where* the data is stored.\n",
    "\n",
    "**When to use a memory mapped object?**\n",
    "\n",
    "In situations you will encounter: not often. However when pre-processing can take a lot of time it can become a bottleneck, slowing down model fitting. In this case you might consider pre-processing everything once and storing it in a memmap object for quick access.\n",
    "\n",
    "-----\n",
    "For completeness sake, the cell below illustrates how to open a memmap object. **Note that** the shape needs to be known when opening it, as it's just a binary blob of data on the disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UacRRlQG8DUl",
    "outputId": "a5776a10-169f-42a7-dcb4-04eb0805f614"
   },
   "outputs": [],
   "source": [
    "#re-open memmap \n",
    "X = np.memmap('X.mmap', mode='r', dtype=np.uint8, shape=(50000, 32, 32, 3))\n",
    "\n",
    "#plot image\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(X[0])\n",
    "plt.show()\n",
    "\n",
    "del X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uxb4X5El8DUn"
   },
   "source": [
    "### Using a Data Generator\n",
    "\n",
    "In the exercise 1 today you learned to make a data generator. In general we recommend this approach in most situations. You could also combine approaches. For example, if your data requires a lot of pre-processing time, you might consider making a memory mapped object containing the data, or a folder with processed images. You can then use a data generator to load these.\n",
    "\n",
    "-----\n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "Implement a data generator below to train for the CelebA data subset.\n",
    "\n",
    "- The filelist and labels are pre-loaded for you.\n",
    "- Ensure the order of the output labels is random\n",
    "    - **Tip:** you can generate a list of indices, shuffle that, and use to recover the corresponding image and label\n",
    "- It should include at least one augmentation option with a 50% chance of augmenting each image\n",
    "    - See 2.4 for examples of augmentation.\n",
    "- Make sure you normalize the image and label!\n",
    "    \n",
    "**Be smart about it: re-use the functions you wrote above!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "f_UYKH4C8DUo"
   },
   "outputs": [],
   "source": [
    "filelist = glob('celeba_larger/data/*.jpg')\n",
    "labels = pd.read_csv('celeba_larger/labels/list_bbox_celeba.txt').values[:,1:,]\n",
    "\n",
    "def dataGen(filelist, labels, batch_size=32, max_size=100):\n",
    "    \n",
    "    #sanity check\n",
    "    assert len(filelist) == len(labels)\n",
    "    \n",
    "    ###Start of coding segment###\n",
    "    #Complete the code below\n",
    "    \n",
    "    indices = ...\n",
    "    \n",
    "    #Remember generators need to run infinitely\n",
    "    while True:\n",
    "\n",
    "        ...\n",
    "        \n",
    "        #return the batch with yield, ensuring the function keeps running\n",
    "        #for testing on a single batch, use 'return'\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "as-lr6Co8DUq"
   },
   "source": [
    "**Exercise:**\n",
    "\n",
    "Test the data generator you've just created.\n",
    "\n",
    "- Have it output a batch of 16 images\n",
    "- Visualise using plt.imshow as we did earlier\n",
    "\n",
    "**Hint:** temporarily replacing 'yield' with with 'return' is an easy way to prevent the data generator from running infinitely once you call it. Don't forget to run the cell after you've replaced it, and **don't forget to change it back** once you've finished testing it and it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "91Ja_5s68DUq",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Write a function to test the data generator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MdT4D0eh8DUt"
   },
   "source": [
    "## 3.3 - Visualising your training data\n",
    "\n",
    "We recommend always visualising your training data after pre-processing, and after running through the data generator, because this is a phase where mistakes often happen that affect learning later on. \n",
    "\n",
    "One of the common mistakes when working with image data, is that OpenCV and NumPy have reversed X/Y axis orders. You might also scale the labels wrongly or make some other mistake. By visualising a few instances of the data, you can catch mistakes quickly.\n",
    "\n",
    "**Exercise:** \n",
    "\n",
    "Write a function that takes an image and a face bounding box of the CelebA dataset, and visualises the annotated bounding box around the face.\n",
    "\n",
    "- The format of the bounding box in this set is [x1, y1, width, height]\n",
    "\n",
    "[hint](https://docs.opencv.org/2.4/modules/core/doc/drawing_functions.html#rectangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "XH2lS5bQ8DUu",
    "outputId": "355b7989-58b7-4115-a738-17282a32cb19"
   },
   "outputs": [],
   "source": [
    "def visualise_label(image, label):\n",
    "    '''\n",
    "    function that takes an image and label,\n",
    "    and uses opencv to visualise it.\n",
    "    '''\n",
    "    \n",
    "    ###Start of coding segment###\n",
    "    marked = cv2...\n",
    "    \n",
    "    return marked\n",
    "\n",
    "    ###End of coding segment\n",
    "\n",
    "\n",
    "#Load first image and first label\n",
    "im = cv2.imread('celeba_larger/data/100001.jpg')\n",
    "labels = pd.read_csv('celeba_larger/labels/list_bbox_celeba.txt')\n",
    "\n",
    "#then we'll run your pre-processing function and plot the result\n",
    "resized_img, resized_label = pre_process(im, labels[1:2].values[0][1:],\n",
    "                                        max_size=200)\n",
    "marked = visualise_label(resized_img, resized_label)\n",
    "\n",
    "#finally we'll plot the result\n",
    "#alternatively you can plot inside the function, uncomment the following lines if you did\n",
    "plt.imshow(marked[...,::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nloHddUL8DUw"
   },
   "source": [
    "### 3.4 - Fitting your Model\n",
    "\n",
    "When fitting your model, there's interesting tricks we can do to make your life easier. \n",
    "\n",
    "In this section we'll show you how to:\n",
    "- save models during training\n",
    "- save progress statistics of training to a log file (loss, accuracy)\n",
    "- automated early stopping\n",
    "\n",
    "First let's get to work on saving your work between epochs. This is especially useful when you're working with models that take a long time to fit. They might start overfitting, in which case you'd want to go back to an earlier iteration. Or your computer might crash, power might fail, or any other nasty thing might happen.\n",
    "\n",
    "These things in Keras are done by so-called 'callbacks'. A callback is basically a function that gets called at the end of each epoch. \n",
    "\n",
    "**Exercise:**\n",
    "\n",
    "You don't need to complete the code below. Do take a look at how we implement the different callbacks and model fitting.\n",
    "\n",
    "- Take note of the callback arguments and compare with [the Keras API here](https://keras.io/callbacks/)\n",
    "- Note we set epochs higher than necessary, and let the early stopper do its work.\n",
    "- We set a custom loss function like we did before. We want to predict 2d coordinates. The euclidean distance is a simple but effective measure of error.\n",
    "\n",
    "Run the cell below after you've understood its contents. Let's see if you implemented the previous functions correctly and if we can get the model to learn something!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6yPz6Jdi8DUx",
    "outputId": "dd7f888e-4014-47cc-860e-d248a8b38b66"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('Models/'):\n",
    "    os.mkdir('Models/')\n",
    "\n",
    "from misc import convnet\n",
    "from keras import callbacks\n",
    "import keras.backend as K\n",
    "\n",
    "#Define custom loss function\n",
    "def euclidean_distance(y_true, y_pred):\n",
    "    return K.sqrt(K.sum(K.square(y_true - y_pred), axis=-1, keepdims=True))\n",
    "\n",
    "#We define the filelist, labels, and split 1900/100\n",
    "filelist = glob('celeba_larger/data/*.jpg')\n",
    "labels = pd.read_csv('celeba_larger/labels/list_bbox_celeba.txt').values[:,1:,]\n",
    "\n",
    "#Split the data 1900/100\n",
    "files_train = filelist[:1900]\n",
    "labels_train = labels[:1900]\n",
    "files_val = filelist[1900:]\n",
    "labels_val = labels[1900:]\n",
    "\n",
    "#load and compile the model\n",
    "model = convnet.build_model(input_shape=(100,100,3), classes=4, final_activation='sigmoid')\n",
    "model.compile(loss=euclidean_distance,\n",
    "              optimizer='adamax',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#we define where to save models\n",
    "filepath = 'Models/my_model.hdf5'\n",
    "#we define the ModelCheckpoint callback\n",
    "saver = callbacks.ModelCheckpoint(filepath, monitor='val_loss', \n",
    "                                  verbose=1, save_best_only=True, \n",
    "                                  mode='min', period=1)\n",
    "#we define the CSVLogger callback\n",
    "logger = callbacks.CSVLogger('Models/trainingresults.log')\n",
    "#we define the EalyStopping callback\n",
    "early_stopper = callbacks.EarlyStopping(monitor='val_loss', patience=3, mode='min',\n",
    "                                        verbose=1, restore_best_weights=True)\n",
    "#Important: put all callback functions in a list\n",
    "callbacklist = [saver, logger, early_stopper]\n",
    "\n",
    "#And specify the list in the fit() function:\n",
    "model.fit_generator(dataGen(files_train, \n",
    "                            labels_train, \n",
    "                            batch_size=32, \n",
    "                            max_size=100),\n",
    "                    epochs=100,\n",
    "                    steps_per_epoch = len(filelist) // 32,\n",
    "                    validation_data=(dataGen(files_val, labels_val,\n",
    "                                             batch_size=10,\n",
    "                                             max_size=100)),\n",
    "                    validation_steps = 100 // 10,\n",
    "                    callbacks = callbacklist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "xYhgUv5j8DU0"
   },
   "source": [
    "## 3.5 - Testing and Visualising Results\n",
    "\n",
    "Now we come to the last segment of this notebook. Well done on getting this far!\n",
    "\n",
    "\n",
    "\n",
    "Let's test your model, run the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3293
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "WC6AMOOM8DU0",
    "outputId": "0c3d4a92-f9ec-41da-84f5-807a70e84a46",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testdata = utils.prepare_celeba_testdata(max_size=100, c_channels=3)\n",
    "    \n",
    "Y = model.predict(np.asarray(testdata))\n",
    "\n",
    "for prediction, img in zip(Y, testdata):\n",
    "    img = np.uint8(img * 255)\n",
    "    prediction = prediction * 100\n",
    "    visualised = visualise_label(img, prediction)\n",
    "\n",
    "    plt.imshow(visualised[...,::-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6eKWvCJ8DU3"
   },
   "source": [
    "**Are you satisfied?**\n",
    "\n",
    "Likely the model does a few images quite well and a few less well. **Why do you think this is the case, would it help to get more training data?**\n",
    "\n",
    "We'll give the answer away and say that indeed, more data is key in this problem (more in exercise 4 on detecting learning problems!). For example, we trained a slightly changed model with about 10 times *less* weights on a lot more data (200K images). Run the cell below to view how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3293
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "w6xVIOYs8DU3",
    "outputId": "99df53ab-974c-4699-bc4c-dcd1f62e8aa2",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "keras.losses.euc_dist_keras = euclidean_distance\n",
    "\n",
    "model = load_model('misc/bb_model.hdf5')\n",
    "\n",
    "testdata = utils.prepare_celeba_testdata(max_size=300, c_channels=1)\n",
    "    \n",
    "Y = model.predict(np.asarray(testdata))\n",
    "\n",
    "for prediction, img in zip(Y, testdata):\n",
    "    img = np.uint8(img * 255)\n",
    "    prediction = prediction * 300\n",
    "    visualised = cv2.rectangle(img, (prediction[0], prediction[1]), \n",
    "                               (prediction[2], prediction[3]), (255,255,255),\n",
    "                               thickness=2)\n",
    "\n",
    "    plt.imshow(visualised[:,:,-1], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "CSIUihYq8DU6",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise_3_Structuring_your_Deep_Learning_Project.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
